## 캐싱 기술

- 데이터베이스나 데이터 저장소에 있는 디스크 히트는 매우 비싸기 때문에 최대한 피해야 한다
- 이를 달성하는 방법 한 가지는 메모리에 있는 그 데이터베이스를 캐시 내부에 캐싱하는 것이다

### 캐시 되지 않은 아키텍처

- 데이터베이스를 직접 히트하는 경우
    - 최상단의 클라이언트가 인터넷을 통해 로드 밸런서와 하드웨어 장치나 서비스 플릿에서 구동하는 소프트웨어와 소통할 것이다.
    - 로드 밸런서는 기본적으로 트래픽을 작업의 종류에 따라 애플리케이션 서버나 웹 서버로 구성된 수평적으로 분산된 플릿에 분산하게 된다.
    - 여기서는 모두가 커다란 데이터베이스 1개와 대화하고 있어 커다란 병목 현상이 있다.
        - 분산된 모든 앱 서버에서 디스크를 히트하면 데이터베이스를 무너트릴 수도 있다.
        - 하드 드라이브가 많고 디스크 헤드도 많아 동시 작업량이 제한된다.
- 주로 데이터베이스는 자체적으로 내부에 캐싱을 보유하고 있지만, 호스트 하나의 메모리에는 한계가 있으므로 이걸로는 충분하지 않다.
- 분산된 데이터베이스 시스템이라도 애플리케이션 호스트에 더 가깝게 캐시를 두는 것이 좋다. 이들은 모두 각각 데이터 센터에 존재할 수 있으므로 해당 데이터 센터로 건너뛰거나 해당 데이터베이스 히트를 피하는 편이 좋다.
- 해결 방법 : 캐싱 층을 도입한다.

### Caching Layers

- Caching Layers : 애플리케이션 서버 옆에 있는 다른 서버들의 플릿으로, 데이터베이스로 유입되어 온 데이터의 메모리 내 사본을 유지한다.
- 이를 통해 데이터베이스에 가장 최근이나 가장 자주 발생한 히트를 기록하고, 이를 메모리에 캐시 된 상태를 유지하여 큰 병목 구조의 데이터베이스에서 디스크 히트보다 훨씬 빠르게 접근할 수 있게 된다.
- 또한 원한다면 애플리케이션 플릿과 별도로 캐싱 플릿으로 확장할 수 있다.
    - 캐시를 애플리케이션 서버 내부에 실제로 구축하는 방법
        - 간편한 방법이지만 독자적으로 분리된 캐싱 서버 플릿을 보유하는 것이 더 나을 수 있다.
        - 이를 통해 애플리케이션 호스트와 별개로 확장할 수 있게 되고, 만약 데이터베이스의 로드를 더욱 최소화하고 싶다면 캐싱 층에 더 많은 호스트를 배치할 수 있다.
        - 따라서 메모리 내부에 두는 것은 데이터베이스 히트 시 성능을 크게 향상시킬 수 있는 한 가지 방법이다.

### 캐시 작동 방식

- 주로 일종의 수평으로 확장된 플릿이며 여기에는 규격화된 솔루션이 존재한다
- 본질적으로 웹 서버나 애플리케이션 서버가 될 클라이언트는 제시된 서버에 데이터베이스 호출을 위한 요청을 해시 할 것이다
- 즉, 원하는 키에 몇 가지 수학적 함수를 적용하게 되고, 키에 따라 캐싱 호스트가 달라지며, 캐싱 호스트가 데이터의 세그먼트 일부를 담당한다.
- 이것이 캐시 서버의 전체 플릿에 정보를 분산하는 방법이다.
- 모든 캐시 서버는 아래 데이터베이스에 있는 데이터 중 일부 부분집합에 관여한다.
- 그리고 해시 함수는 어떤 서버와 대화할지를 빠르게 매핑할 수 있도록 도와준다.

### 캐시 만료 정책

- 데이터가 캐시 된 기간을 결정할 캐시 만료 정책
- 스마트 캐시
    - 진행 상황에 따라 기록 및 업데이트되는 내용을 모니터링하고 캐시 입력을 무효화하는 과정을 똑똑하게 수행한다.
    - 따라서 이 경우 데이터의 오래됨 여부는 큰 문제가 되지는 않겠지만, 얼마 동안 보관해야 할 지를 고려할 필요가 있다.
- 핫스팟 문제
    - 한 서버에는 무명 배우에 대한 정보가 있다고 하고 또 다른 서버에는 브래드 피트나 완전 유명한 배우가 있다고 가정할 때, 다들 브래드 피트를 검색한다는 것이 문제이다. 즉 브래드 피트나 가장 좋아하는 배우에 대한 데이터를 호스팅하는 서버로 많은 트래픽을 보내는 결과를 초래하게 될 것이다.
    - 따라서 캐싱 솔루션은 단순히 키 자체만을 해싱하는 데서 그치는 것이 아니라, 실제로는 낮은 분산을 감안해야 한다. 즉 브래드 피트로 향하는 트래픽이 많이 포착되었으므로 브래드 피트 전용 서버를 구축한다던가, 다수의 서버 호스트 상에 브래드 피트의 데이터를 분산하는 등의 방식이 있다.
- 초기 시작 문제
    - 어시스턴트 DB 를 운영하기 위해 캐싱에 의존하는 경우, 그 캐싱 서버 층을 처음 켤 때 문제가 생긴다.
    - 이때 문제는 방금 처음 가동했거나 캐시가 비어있을 때 메모리에 아무 것도 저장되지 않은 상태인 것이다.
    - 그럼 캐시가 준비되기 전까지 모든 요청을 일일이 데이터베이스에 히트(모든 초기 트래픽이 데이터베이스로 유입)하게 될 것이다.
    - 이제 이 초당 수천 건의 트랜잭션이 들어오면, 데이터베이스로 유입되는 최초의 트래픽 폭발이 데이터베이스를 충돌 및 고장 낼 수도 있다.
    - 해결 방법 : 외부 세계에 드러내기 전 먼저 캐시를 준비할 별도의 절차를 둔다.
        - 모의 요청을 가장하여 캐싱 층에 트래픽을 인위적으로 보내는 과정을 진행한다던가, 어제 나온 백로그를 재생하는 등의 방법이 있다.
        - 확실하게 준비됐다는 확신이 없다면, 시스템을 실제로 다시 켜거나 캐싱 층에 데이터 주입을 하지 않는 게 이 문제의 한가지 해결책이다.

### 정리

- 수평으로 분산된 캐시는 쓰기보다 읽기가 많은 경우 유용하다.
- 캐시 만료 정책과 관련하여, 데이터를 얼마나 오래 캐시 된 상태로 유지시켜야 할지 생각해야 한다. 너무 짧게 설정하는 경우 캐시의 효과가 없을 것이다.
- 핫스팟 문제를 생각해 보고, 데이터베이스가 망가지지 않도록 첫 시동(초기 시작 문제)을 어떻게 걸지도 생각해 봐야 한다.